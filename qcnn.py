# -*- coding: utf-8 -*-
"""O-QCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-xeoCYbVNB8JRiVVzUeerciVRR2FwCF5
"""

!pip install tensorflow torch torchvision qiskit qiskit-machine-learning matplotlib

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Path to your dataset folder
DATASET_PATH = "/content/drive/MyDrive/b"

# Image size (make it small for QCNN, e.g., 32x32 or 64x64)
IMG_SIZE = (32, 32)
BATCH_SIZE = 16

# Data generator with normalization + split
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_data = datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical",   # since you have 4 classes
    subset="training"
)

val_data = datagen.flow_from_directory(
    DATASET_PATH,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset="validation"
)

import torch
import torch.nn as nn
import torch.nn.functional as F
from qiskit_machine_learning.connectors import TorchConnector
from qiskit_machine_learning.neural_networks import EstimatorQNN
from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap
from qiskit.primitives import Sampler

# Quantum part setup
num_qubits = 4
feature_map = ZZFeatureMap(num_qubits)
ansatz = RealAmplitudes(num_qubits, reps=1)
sampler = Sampler()

qnn = EstimatorQNN(
    circuit=feature_map.compose(ansatz),
    input_params=feature_map.parameters,
    weight_params=ansatz.parameters
)

q_layer = TorchConnector(qnn)

class HybridQCNN(nn.Module):
    def __init__(self):
        super(HybridQCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=2)
        self.fc1 = nn.Linear(8 * 15 * 15, num_qubits)  # adjust for 32x32 images
        self.q_layer = q_layer
        self.fc2 = nn.Linear(1, 4)  # 4 output classes

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = x.reshape(x.size(0), -1)   # ✅ FIXED: use reshape instead of view
        x = self.fc1(x)
        x = self.q_layer(x)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

model = HybridQCNN()
dummy = torch.randn(2, 3, 32, 32)  # 2 images, 3 channels, 32x32
print(model(dummy).shape)

import torch
import torch.optim as optim

model = HybridQCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

EPOCHS = 10

for epoch in range(EPOCHS):
    print(f"\nEpoch {epoch+1}/{EPOCHS}")
    running_loss = 0.0
    correct, total = 0, 0

    for i, (x, y) in enumerate(train_data):
        x = torch.tensor(x, dtype=torch.float32).permute(0,3,1,2)  # NHWC → NCHW
        y = torch.tensor(y, dtype=torch.float32)

        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, torch.argmax(y, dim=1))
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        preds = torch.argmax(outputs, dim=1)
        labels = torch.argmax(y, dim=1)
        correct += (preds == labels).sum().item()
        total += y.size(0)

        if i % 20 == 0:  # print progress every 20 batches
            print(f"Step {i}, Loss: {loss.item():.4f}")

        if i == 100:  # limit steps for faster testing in Colab
            break

    acc = correct / total
    print(f"Epoch {epoch+1} Loss: {running_loss/total:.4f}, Train Accuracy: {acc:.2f}")

model.eval()
correct, total = 0, 0

for x, y in val_data:
    x = torch.tensor(x, dtype=torch.float32).permute(0,3,1,2)
    y = torch.tensor(y, dtype=torch.float32)

    outputs = model(x)
    preds = torch.argmax(outputs, dim=1)
    labels = torch.argmax(y, dim=1)

    correct += (preds == labels).sum().item()
    total += y.size(0)
    if total > 500:   # avoid looping forever in generator
        break

print(f"Validation Accuracy: {correct/total:.2f}")

#to shaow the output

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

y_true = []
y_pred = []

model.eval()
for x, y in val_data:
    x = torch.tensor(x, dtype=torch.float32).permute(0,3,1,2)
    y = torch.tensor(y, dtype=torch.float32)

    outputs = model(x)
    preds = torch.argmax(outputs, dim=1)
    labels = torch.argmax(y, dim=1)

    y_true.extend(labels.numpy())
    y_pred.extend(preds.detach().numpy())

    if len(y_true) > 500:  # limit for speed
        break

acc = accuracy_score(y_true, y_pred)
print(f"Validation Accuracy: {acc:.2f}")
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=val_data.class_indices.keys()))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues",
            xticklabels=val_data.class_indices.keys(),
            yticklabels=val_data.class_indices.keys())
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix - Hybrid QCNN")
plt.show()

# Take one batch from validation
x_batch, y_batch = next(iter(val_data))

x_batch_torch = torch.tensor(x_batch, dtype=torch.float32).permute(0,3,1,2)
outputs = model(x_batch_torch)
preds = torch.argmax(outputs, dim=1)

# Map class indices back to labels
class_labels = {v: k for k, v in val_data.class_indices.items()}

plt.figure(figsize=(12, 6))
for i in range(6):  # show 6 sample images
    plt.subplot(2, 3, i+1)
    plt.imshow(x_batch[i])
    true_label = class_labels[np.argmax(y_batch[i])]
    pred_label = class_labels[preds[i].item()]
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis("off")
plt.show()

